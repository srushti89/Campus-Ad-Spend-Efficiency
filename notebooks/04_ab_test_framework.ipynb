{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065cae84",
   "metadata": {},
   "source": [
    "# ðŸ§ª A/B Testing Framework for Ad Spend Optimization\n",
    "\n",
    "**Goal:** Design and implement a statistical framework to test budget reallocation strategies.\n",
    "\n",
    "This notebook covers:\n",
    "- **Power Analysis** - determine required sample sizes\n",
    "- **Test Design** - randomization and control strategies  \n",
    "- **Statistical Testing** - significance testing for conversion rates\n",
    "- **Confidence Intervals** - estimate effect sizes\n",
    "- **Sequential Testing** - early stopping criteria\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62246e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, chi2_contingency, fisher_exact\n",
    "from statsmodels.stats.power import ttest_power, zt_ind_solve_power\n",
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ðŸ§ª A/B Testing framework loaded!\")\n",
    "\n",
    "class ABTestFramework:\n",
    "    \"\"\"\n",
    "    A comprehensive A/B testing framework for ad spend optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=0.05, power=0.8):\n",
    "        self.alpha = alpha  # Significance level\n",
    "        self.power = power  # Statistical power\n",
    "        \n",
    "    def calculate_sample_size(self, baseline_rate, minimum_detectable_effect, \n",
    "                            alternative='two-sided'):\n",
    "        \"\"\"\n",
    "        Calculate required sample size for proportion test\n",
    "        \n",
    "        Parameters:\n",
    "        - baseline_rate: Current conversion rate\n",
    "        - minimum_detectable_effect: Minimum effect size to detect (e.g., 0.1 for 10% relative improvement)\n",
    "        - alternative: 'two-sided' or 'larger'\n",
    "        \"\"\"\n",
    "        \n",
    "        effect_size = baseline_rate * minimum_detectable_effect\n",
    "        \n",
    "        # Calculate required sample size\n",
    "        if alternative == 'two-sided':\n",
    "            z_alpha = norm.ppf(1 - self.alpha/2)\n",
    "            z_beta = norm.ppf(self.power)\n",
    "        else:\n",
    "            z_alpha = norm.ppf(1 - self.alpha)\n",
    "            z_beta = norm.ppf(self.power)\n",
    "        \n",
    "        # Using normal approximation for proportion test\n",
    "        p1 = baseline_rate\n",
    "        p2 = baseline_rate + effect_size\n",
    "        p_pooled = (p1 + p2) / 2\n",
    "        \n",
    "        numerator = (z_alpha * np.sqrt(2 * p_pooled * (1 - p_pooled)) + \n",
    "                    z_beta * np.sqrt(p1 * (1 - p1) + p2 * (1 - p2)))**2\n",
    "        \n",
    "        denominator = (p2 - p1)**2\n",
    "        \n",
    "        n_per_group = numerator / denominator\n",
    "        \n",
    "        return int(np.ceil(n_per_group))\n",
    "    \n",
    "    def run_proportion_test(self, control_conversions, control_visitors, \n",
    "                          treatment_conversions, treatment_visitors):\n",
    "        \"\"\"\n",
    "        Run a two-proportion z-test\n",
    "        \"\"\"\n",
    "        \n",
    "        # Calculate conversion rates\n",
    "        control_rate = control_conversions / control_visitors\n",
    "        treatment_rate = treatment_conversions / treatment_visitors\n",
    "        \n",
    "        # Run the test\n",
    "        count = np.array([treatment_conversions, control_conversions])\n",
    "        nobs = np.array([treatment_visitors, control_visitors])\n",
    "        \n",
    "        z_stat, p_value = proportions_ztest(count, nobs)\n",
    "        \n",
    "        # Calculate confidence interval for the difference\n",
    "        diff = treatment_rate - control_rate\n",
    "        se_diff = np.sqrt((control_rate * (1 - control_rate) / control_visitors) + \n",
    "                         (treatment_rate * (1 - treatment_rate) / treatment_visitors))\n",
    "        \n",
    "        ci_lower = diff - 1.96 * se_diff\n",
    "        ci_upper = diff + 1.96 * se_diff\n",
    "        \n",
    "        # Calculate relative improvement\n",
    "        relative_improvement = ((treatment_rate - control_rate) / control_rate) * 100\n",
    "        \n",
    "        results = {\n",
    "            'control_rate': control_rate,\n",
    "            'treatment_rate': treatment_rate,\n",
    "            'difference': diff,\n",
    "            'relative_improvement_pct': relative_improvement,\n",
    "            'z_statistic': z_stat,\n",
    "            'p_value': p_value,\n",
    "            'is_significant': p_value < self.alpha,\n",
    "            'confidence_interval': (ci_lower, ci_upper)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def bayesian_ab_test(self, control_conversions, control_visitors,\n",
    "                        treatment_conversions, treatment_visitors,\n",
    "                        prior_alpha=1, prior_beta=1):\n",
    "        \"\"\"\n",
    "        Bayesian A/B test using Beta-Binomial model\n",
    "        \"\"\"\n",
    "        \n",
    "        # Posterior parameters for control\n",
    "        control_alpha_post = prior_alpha + control_conversions\n",
    "        control_beta_post = prior_beta + control_visitors - control_conversions\n",
    "        \n",
    "        # Posterior parameters for treatment  \n",
    "        treatment_alpha_post = prior_alpha + treatment_conversions\n",
    "        treatment_beta_post = prior_beta + treatment_visitors - treatment_conversions\n",
    "        \n",
    "        # Sample from posteriors\n",
    "        n_samples = 100000\n",
    "        control_samples = np.random.beta(control_alpha_post, control_beta_post, n_samples)\n",
    "        treatment_samples = np.random.beta(treatment_alpha_post, treatment_beta_post, n_samples)\n",
    "        \n",
    "        # Calculate probability that treatment > control\n",
    "        prob_treatment_better = np.mean(treatment_samples > control_samples)\n",
    "        \n",
    "        # Calculate expected lift\n",
    "        expected_lift = np.mean((treatment_samples - control_samples) / control_samples) * 100\n",
    "        \n",
    "        # Credible intervals\n",
    "        lift_samples = (treatment_samples - control_samples) / control_samples * 100\n",
    "        lift_ci = np.percentile(lift_samples, [2.5, 97.5])\n",
    "        \n",
    "        results = {\n",
    "            'probability_treatment_better': prob_treatment_better,\n",
    "            'expected_lift_pct': expected_lift,\n",
    "            'lift_credible_interval': lift_ci,\n",
    "            'control_posterior_mean': control_alpha_post / (control_alpha_post + control_beta_post),\n",
    "            'treatment_posterior_mean': treatment_alpha_post / (treatment_alpha_post + treatment_beta_post)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def sequential_test(self, data, method='obrien_fleming'):\n",
    "        \"\"\"\n",
    "        Sequential testing with early stopping\n",
    "        \"\"\"\n",
    "        # Implementation for sequential testing would go here\n",
    "        # This is a simplified version\n",
    "        pass\n",
    "    \n",
    "    def plot_power_analysis(self, baseline_rate, effect_sizes, sample_sizes):\n",
    "        \"\"\"\n",
    "        Plot power curves for different effect sizes and sample sizes\n",
    "        \"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Power vs Effect Size\n",
    "        powers = []\n",
    "        for effect in effect_sizes:\n",
    "            n = self.calculate_sample_size(baseline_rate, effect)\n",
    "            power = self.calculate_power(baseline_rate, baseline_rate * (1 + effect), n)\n",
    "            powers.append(power)\n",
    "        \n",
    "        ax1.plot(np.array(effect_sizes) * 100, powers, 'b-', linewidth=2)\n",
    "        ax1.axhline(y=0.8, color='r', linestyle='--', alpha=0.7, label='80% Power')\n",
    "        ax1.set_xlabel('Minimum Detectable Effect (%)')\n",
    "        ax1.set_ylabel('Statistical Power')\n",
    "        ax1.set_title('Power vs Effect Size')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Sample Size vs Effect Size\n",
    "        sample_sizes_needed = [self.calculate_sample_size(baseline_rate, effect) for effect in effect_sizes]\n",
    "        \n",
    "        ax2.plot(np.array(effect_sizes) * 100, sample_sizes_needed, 'g-', linewidth=2)\n",
    "        ax2.set_xlabel('Minimum Detectable Effect (%)')\n",
    "        ax2.set_ylabel('Required Sample Size (per group)')\n",
    "        ax2.set_title('Sample Size vs Effect Size')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def calculate_power(self, p1, p2, n):\n",
    "        \"\"\"Calculate statistical power for given parameters\"\"\"\n",
    "        effect_size = abs(p2 - p1) / np.sqrt(p1 * (1 - p1))\n",
    "        power = zt_ind_solve_power(effect_size, nobs1=n, alpha=self.alpha)\n",
    "        return power\n",
    "\n",
    "# Initialize the framework\n",
    "ab_framework = ABTestFramework(alpha=0.05, power=0.8)\n",
    "print(\"âœ… A/B Testing framework initialized!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
